{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdaccdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.9.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cb2e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR10 데이터를 이용한 RESNET 설계\n",
    "#1. 하이퍼 파라미터\n",
    "BATCH_SIZE =  32 #한 배치당 32개 이미지\n",
    "EPOCHS = 30 # 전체 데이터 셋을 10번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7008448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터 다운로드. Train Set, Test set 분리\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../data/CIFAR_10\",\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform = transforms.ToTensor())\n",
    "#train_set download. ToTensor()로 255스칼라값을 데이터를 0~1로 정규화.\n",
    "#과적화 방지를 위해.\n",
    "test_dataset = datasets.CIFAR10(root=\"../data/CIFAR_10\",\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform = transforms.ToTensor())\n",
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True) # 순서가 암기되는것을 막기위해.\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363a438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET 18 ?\n",
    "#계산하면 14. no bottleneck.\n",
    "#cifar-10 데이터라서, 작게 쌓은것으로 생각.\n",
    "class BasicBlock(nn.Module):\n",
    "    # 반복적으로 이용되는 block\n",
    "    def __init__(self, in_planes,planes,stride=1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes,planes,\n",
    "                               kernel_size=3,\n",
    "                               stride = stride,# 첫번째 레이어만 stride를 가변적으로\n",
    "                               padding=1,\n",
    "                               bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes,planes,\n",
    "                               kernel_size=3,\n",
    "                               stride = 1,#여기서는 이미지 사이즈 그대로 유지\n",
    "                               padding=1,\n",
    "                               bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        #identity map. 크기가 같을 때.\n",
    "        self.shortcut = nn.Sequential()#Skip Connection 정의\n",
    "        \n",
    "        #만약, stride가 달라지고, 인풋과 아웃풋이 크기가 다르면, Projection하는 개념.\n",
    "        #stride가 달라져도, 한번만 conv해주면 된다. \n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                in_planes,planes, # 더하려면 depth가 같아야해서 conv2와 output사이즈를 같게 \n",
    "                kernel_size = 1, #1x1로 데이터는 그대로 유지하고 합.\n",
    "                bias=False,\n",
    "                stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # skip connection\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1=nn.Conv2d(3,16, # 3채널 16 피처맵으로 시작\n",
    "                             kernel_size=3,\n",
    "                             stride = 1,\n",
    "                             padding = 1,\n",
    "                             bias = False\n",
    "                            )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16,2,stride=1)#16피처맵  레이어 4개\n",
    "        self.layer2 = self._make_layer(32,2,stride=2)#32피처맵  레이어 4개\n",
    "        self.layer3 = self._make_layer(64,2,stride=2)#32피처맵  레이어 4개\n",
    "        self.linear = nn.Linear(64,num_classes)\n",
    "            \n",
    "    def _make_layer(self,planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes,planes,stride))\n",
    "            self.in_planes=planes#출력결과로 반영\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x))) #첫번째 레이어\n",
    "        out = self.layer1(out)# 2~5\n",
    "        out = self.layer2(out)# 6~9\n",
    "        out = self.layer3(out)# 10~13\n",
    "        out = F.avg_pool2d(out,8)\n",
    "        out = out.view(out.size(0),-1)#데이터 펴기\n",
    "        out = self.linear(out)#데이터 분류\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1835b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Optimizer, Objective Function\n",
    "model = ResNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#원핫 인코딩값의 loss는 crossEntropyLoss로 비교\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0bca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce39f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, test 데이터로 모델 성능확인\n",
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            #print(output.max(1,keepdim=True))\n",
    "            #print(prediction)\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss,test_accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eb840ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:1], \tTest Loss:0.0188 \tTest Accuracy: 80.42 %\n",
      "\n",
      "\n",
      "[EPOCH:2], \tTest Loss:0.0184 \tTest Accuracy: 81.96 %\n",
      "\n",
      "\n",
      "[EPOCH:3], \tTest Loss:0.0184 \tTest Accuracy: 82.04 %\n",
      "\n",
      "\n",
      "[EPOCH:4], \tTest Loss:0.0190 \tTest Accuracy: 82.19 %\n",
      "\n",
      "\n",
      "[EPOCH:5], \tTest Loss:0.0197 \tTest Accuracy: 81.75 %\n",
      "\n",
      "\n",
      "[EPOCH:6], \tTest Loss:0.0199 \tTest Accuracy: 81.73 %\n",
      "\n",
      "\n",
      "[EPOCH:7], \tTest Loss:0.0220 \tTest Accuracy: 81.07 %\n",
      "\n",
      "\n",
      "[EPOCH:8], \tTest Loss:0.0233 \tTest Accuracy: 80.17 %\n",
      "\n",
      "\n",
      "[EPOCH:9], \tTest Loss:0.0212 \tTest Accuracy: 81.98 %\n",
      "\n",
      "\n",
      "[EPOCH:10], \tTest Loss:0.0256 \tTest Accuracy: 80.08 %\n",
      "\n",
      "\n",
      "[EPOCH:11], \tTest Loss:0.0240 \tTest Accuracy: 81.11 %\n",
      "\n",
      "\n",
      "[EPOCH:12], \tTest Loss:0.0230 \tTest Accuracy: 81.36 %\n",
      "\n",
      "\n",
      "[EPOCH:13], \tTest Loss:0.0255 \tTest Accuracy: 81.07 %\n",
      "\n",
      "\n",
      "[EPOCH:14], \tTest Loss:0.0258 \tTest Accuracy: 81.05 %\n",
      "\n",
      "\n",
      "[EPOCH:15], \tTest Loss:0.0245 \tTest Accuracy: 81.54 %\n",
      "\n",
      "\n",
      "[EPOCH:16], \tTest Loss:0.0252 \tTest Accuracy: 81.37 %\n",
      "\n",
      "\n",
      "[EPOCH:17], \tTest Loss:0.0254 \tTest Accuracy: 81.33 %\n",
      "\n",
      "\n",
      "[EPOCH:18], \tTest Loss:0.0275 \tTest Accuracy: 80.61 %\n",
      "\n",
      "\n",
      "[EPOCH:19], \tTest Loss:0.0254 \tTest Accuracy: 81.90 %\n",
      "\n",
      "\n",
      "[EPOCH:20], \tTest Loss:0.0296 \tTest Accuracy: 79.66 %\n",
      "\n",
      "\n",
      "[EPOCH:21], \tTest Loss:0.0260 \tTest Accuracy: 81.78 %\n",
      "\n",
      "\n",
      "[EPOCH:22], \tTest Loss:0.0288 \tTest Accuracy: 80.25 %\n",
      "\n",
      "\n",
      "[EPOCH:23], \tTest Loss:0.0278 \tTest Accuracy: 81.22 %\n",
      "\n",
      "\n",
      "[EPOCH:24], \tTest Loss:0.0270 \tTest Accuracy: 81.81 %\n",
      "\n",
      "\n",
      "[EPOCH:25], \tTest Loss:0.0280 \tTest Accuracy: 81.01 %\n",
      "\n",
      "\n",
      "[EPOCH:26], \tTest Loss:0.0272 \tTest Accuracy: 82.06 %\n",
      "\n",
      "\n",
      "[EPOCH:27], \tTest Loss:0.0284 \tTest Accuracy: 80.88 %\n",
      "\n",
      "\n",
      "[EPOCH:28], \tTest Loss:0.0289 \tTest Accuracy: 81.00 %\n",
      "\n",
      "\n",
      "[EPOCH:29], \tTest Loss:0.0288 \tTest Accuracy: 81.40 %\n",
      "\n",
      "\n",
      "[EPOCH:30], \tTest Loss:0.0290 \tTest Accuracy: 81.59 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "for Epoch in range(1,EPOCHS+1):\n",
    "    train(model,train_loader,optimizer,log_interval=200)\n",
    "    test_loss,test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH:{}], \\tTest Loss:{:.4f} \\tTest Accuracy: {:.2f} %\\n\".\n",
    "          format(Epoch,test_loss,test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
