{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e49246",
   "metadata": {},
   "source": [
    "# mnist variational auto encoder 예제\n",
    "\n",
    "https://github.com/lyeoni/pytorch-mnist-VAE/blob/master/pytorch-mnist-VAE.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73177a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f6480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ba2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var) # e^(0.5*log_var)\n",
    "        eps = torch.randn_like(std) # std사이즈와 같은 정규분포 랜덤 z값 생성. \n",
    "        \n",
    "        \n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var) \n",
    "        # 왜 encoder 결과가 mu와 log_var 인지?\n",
    "        # 해당 이미지가 mu 에 위치하고, var만큼 퍼져있는 지역에 있다는 의미.\n",
    "        # z라는 랜덤변수를 추출해서, decoder로.\n",
    "        \n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae=vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97956cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53db054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum') #합이 같은지를 비교\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a77b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d4fad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cce490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.683867\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 195.131797\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 174.003652\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 170.172949\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 175.126191\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 169.975957\n",
      "====> Epoch: 1 Average loss: 180.3331\n",
      "====> Test set loss: 163.0279\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 165.500586\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 151.593818\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 164.645508\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 157.385273\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 160.797227\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 156.149180\n",
      "====> Epoch: 2 Average loss: 158.2077\n",
      "====> Test set loss: 155.2007\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 158.445703\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 158.338994\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 149.320742\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 154.243730\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 149.155625\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 147.703154\n",
      "====> Epoch: 3 Average loss: 152.7877\n",
      "====> Test set loss: 151.4892\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 159.992998\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 153.186113\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 150.258125\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 152.530010\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 145.172539\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 147.377207\n",
      "====> Epoch: 4 Average loss: 149.4538\n",
      "====> Test set loss: 148.8531\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 138.717168\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 145.875205\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 151.800205\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 149.265518\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 146.883291\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 148.993535\n",
      "====> Epoch: 5 Average loss: 147.2732\n",
      "====> Test set loss: 146.8766\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 145.122480\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 148.266934\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 140.876621\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 142.230830\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 143.947334\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 148.718506\n",
      "====> Epoch: 6 Average loss: 145.8046\n",
      "====> Test set loss: 145.5623\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 146.495586\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 147.150527\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 150.147881\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 147.856006\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 133.632344\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 160.220684\n",
      "====> Epoch: 7 Average loss: 144.5511\n",
      "====> Test set loss: 145.0618\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 140.388301\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 135.800938\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 142.290684\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 138.102207\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 141.601758\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 139.021582\n",
      "====> Epoch: 8 Average loss: 143.8190\n",
      "====> Test set loss: 143.9456\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 135.052656\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 145.305859\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 143.767969\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 135.812568\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 140.051729\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 145.074609\n",
      "====> Epoch: 9 Average loss: 142.9844\n",
      "====> Test set loss: 143.6042\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 147.747070\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 152.769082\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 130.615547\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 142.896328\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 148.185527\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 143.701162\n",
      "====> Epoch: 10 Average loss: 142.2589\n",
      "====> Test set loss: 143.0996\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 151.341230\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 141.101660\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 140.428467\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 145.833418\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 134.057773\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 141.596221\n",
      "====> Epoch: 11 Average loss: 141.6128\n",
      "====> Test set loss: 142.3903\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 135.179258\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 133.536738\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 142.168047\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 141.294795\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 137.694707\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 142.019111\n",
      "====> Epoch: 12 Average loss: 141.0952\n",
      "====> Test set loss: 142.0226\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 130.728330\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 143.083184\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 146.407637\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 135.462217\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 140.976045\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 136.081348\n",
      "====> Epoch: 13 Average loss: 140.5512\n",
      "====> Test set loss: 141.8452\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 143.192109\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 142.140596\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 138.832246\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 138.382373\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 140.131084\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 141.988545\n",
      "====> Epoch: 14 Average loss: 140.4849\n",
      "====> Test set loss: 141.9205\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 146.317168\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 137.636504\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 141.295410\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 137.271523\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 148.656514\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 141.792861\n",
      "====> Epoch: 15 Average loss: 140.0238\n",
      "====> Test set loss: 141.0907\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 141.815410\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 135.528057\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 140.598057\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 134.720557\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 153.355527\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 139.180000\n",
      "====> Epoch: 16 Average loss: 139.5187\n",
      "====> Test set loss: 140.9740\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 149.466035\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 143.160615\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 136.531768\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 137.580010\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 141.060420\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 148.939990\n",
      "====> Epoch: 17 Average loss: 139.3594\n",
      "====> Test set loss: 140.7515\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 139.451631\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 138.954434\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 144.251260\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 128.008594\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 138.324365\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 154.767148\n",
      "====> Epoch: 18 Average loss: 139.0663\n",
      "====> Test set loss: 140.5119\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 133.590117\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 137.684199\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 139.636094\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 136.433447\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 144.437021\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 148.544307\n",
      "====> Epoch: 19 Average loss: 138.7678\n",
      "====> Test set loss: 140.3353\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 138.816885\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 133.811768\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 136.652666\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 134.797861\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 143.962168\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 139.787861\n",
      "====> Epoch: 20 Average loss: 138.5995\n",
      "====> Test set loss: 140.2477\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 138.364893\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 131.468965\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 141.550342\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 135.073848\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 141.008125\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 137.551064\n",
      "====> Epoch: 21 Average loss: 138.3621\n",
      "====> Test set loss: 140.1502\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 146.058066\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 141.312471\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 136.879160\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 147.077979\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 138.708740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 131.232832\n",
      "====> Epoch: 22 Average loss: 138.0359\n",
      "====> Test set loss: 139.7064\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 148.735469\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 136.594014\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 138.548086\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 140.461250\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 139.803105\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 141.680684\n",
      "====> Epoch: 23 Average loss: 138.0366\n",
      "====> Test set loss: 140.0233\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 139.768584\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 141.773242\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 132.628076\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 142.682412\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 136.555117\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 139.059297\n",
      "====> Epoch: 24 Average loss: 137.5555\n",
      "====> Test set loss: 139.2645\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 138.031787\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 131.931973\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 132.131279\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 138.409375\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 131.076152\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 138.427920\n",
      "====> Epoch: 25 Average loss: 137.6961\n",
      "====> Test set loss: 139.4900\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 140.287285\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 141.297959\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 137.606396\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 135.044551\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 137.219785\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 141.299707\n",
      "====> Epoch: 26 Average loss: 137.4585\n",
      "====> Test set loss: 139.2033\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 148.347207\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 132.006123\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 147.072656\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 133.786445\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 142.730605\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 140.924219\n",
      "====> Epoch: 27 Average loss: 137.1781\n",
      "====> Test set loss: 139.3538\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 137.583818\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 138.872900\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 136.622314\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 138.739229\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 132.483838\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 140.119375\n",
      "====> Epoch: 28 Average loss: 137.1863\n",
      "====> Test set loss: 139.1786\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 137.217324\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 144.013887\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 135.652588\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 137.933545\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 135.813984\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 138.932656\n",
      "====> Epoch: 29 Average loss: 137.0940\n",
      "====> Test set loss: 139.3295\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 135.245322\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 135.951348\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 138.123096\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 137.910889\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 135.152187\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 134.369102\n",
      "====> Epoch: 30 Average loss: 137.0338\n",
      "====> Test set loss: 139.2800\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 139.195684\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 145.443975\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 131.052998\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 129.433945\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 136.887178\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 135.151113\n",
      "====> Epoch: 31 Average loss: 136.7554\n",
      "====> Test set loss: 139.0135\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 133.110615\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 127.857305\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 132.109668\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 132.739131\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 137.865156\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 130.557881\n",
      "====> Epoch: 32 Average loss: 136.7249\n",
      "====> Test set loss: 138.9689\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 130.786621\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 146.439072\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 134.058926\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 142.544883\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 142.659434\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 139.096133\n",
      "====> Epoch: 33 Average loss: 136.5435\n",
      "====> Test set loss: 139.7506\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 133.747754\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 131.561084\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 142.047207\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 129.839844\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 131.228721\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 143.150273\n",
      "====> Epoch: 34 Average loss: 136.3882\n",
      "====> Test set loss: 139.1953\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 135.432676\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 137.519854\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 138.058945\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 133.451221\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 141.081406\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 141.411396\n",
      "====> Epoch: 35 Average loss: 136.1520\n",
      "====> Test set loss: 138.4473\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 132.628994\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 134.488086\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 131.208105\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 125.430234\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 142.662031\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 136.566143\n",
      "====> Epoch: 36 Average loss: 136.2028\n",
      "====> Test set loss: 138.7661\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 138.423740\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 132.983486\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 139.299111\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 139.674570\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 139.746074\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 139.235010\n",
      "====> Epoch: 37 Average loss: 135.9470\n",
      "====> Test set loss: 139.0035\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 139.907266\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 125.861992\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 133.025762\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 136.136953\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 131.566807\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 139.126924\n",
      "====> Epoch: 38 Average loss: 136.3740\n",
      "====> Test set loss: 138.6647\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 135.974160\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 134.215576\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 135.005010\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 132.725469\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 137.951055\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 138.658896\n",
      "====> Epoch: 39 Average loss: 135.8285\n",
      "====> Test set loss: 138.6497\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 137.685840\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 141.936787\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 138.953555\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 140.002021\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 130.868418\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 142.550303\n",
      "====> Epoch: 40 Average loss: 135.6400\n",
      "====> Test set loss: 138.5424\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 131.523789\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 137.932871\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 141.095576\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 130.948838\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 135.654102\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 142.985391\n",
      "====> Epoch: 41 Average loss: 135.4177\n",
      "====> Test set loss: 138.3113\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 136.954023\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 137.696621\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 134.695537\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 129.055820\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 137.925293\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 133.714561\n",
      "====> Epoch: 42 Average loss: 135.5270\n",
      "====> Test set loss: 138.4184\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 139.594072\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 133.221045\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 143.983672\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 135.894346\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 131.620088\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 131.709160\n",
      "====> Epoch: 43 Average loss: 135.5253\n",
      "====> Test set loss: 138.0871\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 132.636777\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 130.343809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 134.360811\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 137.609990\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 137.806387\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 134.041270\n",
      "====> Epoch: 44 Average loss: 135.2151\n",
      "====> Test set loss: 138.2302\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 146.704863\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 135.331992\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 134.255957\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 134.245098\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 136.532969\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 133.092666\n",
      "====> Epoch: 45 Average loss: 135.1306\n",
      "====> Test set loss: 138.4556\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 143.874004\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 139.469844\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 136.076260\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 125.654609\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 132.893281\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 140.751387\n",
      "====> Epoch: 46 Average loss: 134.8991\n",
      "====> Test set loss: 137.6444\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 130.909746\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 140.352568\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 129.583242\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 139.493398\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 139.970898\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 135.962344\n",
      "====> Epoch: 47 Average loss: 134.9415\n",
      "====> Test set loss: 137.9413\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 134.956260\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 129.661475\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 132.545850\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 137.633789\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 143.127666\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 131.599150\n",
      "====> Epoch: 48 Average loss: 134.9872\n",
      "====> Test set loss: 137.9888\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 134.567744\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 136.561494\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 134.952520\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 133.963223\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 138.107510\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 137.991367\n",
      "====> Epoch: 49 Average loss: 134.8480\n",
      "====> Test set loss: 138.1786\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 130.543994\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 140.060137\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 138.354551\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 139.156357\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 131.146250\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 132.757324\n",
      "====> Epoch: 50 Average loss: 134.8789\n",
      "====> Test set loss: 138.0251\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f246be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1add9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "    \n",
    "    save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca899a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
